{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating daily percentage change in stocks using Apache Spark\n",
    "\n",
    "We **extract** the files downloaded from https://www.kaggle.com/jacksoncrow/stock-market-dataset and read the csv format files. In this case we only use 10 stocks to keep the running of the script short.\n",
    "\n",
    "Then we **transform** the data calculting the daily percentage change in stocks by subtracting the opening price from the closing price of each stock and dividing it by the opening price. \n",
    "We add this result in a new column (named as each specific stock) and drop the rest of the columns.\n",
    "We join the new columns to the dataframe 'stocks'. \n",
    "\n",
    "Finally we **load** the dataframe as a parquet file partitioning by year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+----+----+----+----+----+----+----+----+----+-----+\n",
      "|      Date|   A|                  AA|AACG| AAL|AAMC|AAME| AAN|AAOI|AAON| AAP|Year|Month|\n",
      "+----------+----+--------------------+----+----+----+----+----+----+----+----+----+-----+\n",
      "|1963-03-22|null|-0.00155407666901...|null|null|null|null|null|null|null|null|1963|    3|\n",
      "|1964-01-22|null|-0.00221243046520...|null|null|null|null|null|null|null|null|1964|    1|\n",
      "|1968-05-23|null|-0.00350470320111...|null|null|null|null|null|null|null|null|1968|    5|\n",
      "|1968-06-04|null|0.012588933671785681|null|null|null|null|null|null|null|null|1968|    6|\n",
      "|1969-04-03|null|                 0.0|null|null|null|null|null|null|null|null|1969|    4|\n",
      "|1969-07-22|null|-0.01343463765040...|null|null|null|null|null|null|null|null|1969|    7|\n",
      "|1970-01-22|null|0.010925834436531119|null|null|null|null|null|null|null|null|1970|    1|\n",
      "|1971-12-28|null|0.001843297340496...|null|null|null|null|null|null|null|null|1971|   12|\n",
      "|1973-04-27|null|-0.00568183932181...|null|null|null|null|null|null|null|null|1973|    4|\n",
      "|1973-08-02|null|0.034334745463913144|null|null|null|null|null|null|null|null|1973|    8|\n",
      "+----------+----+--------------------+----+----+----+----+----+----+----+----+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "from glob import glob, os\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "schema = StructType([StructField('Date', TimestampType(), True)])\n",
    "\n",
    "stocks = sqlContext.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "\n",
    "#Extract\n",
    "path = '/home/jovyan/stocks10/'\n",
    "for file in sorted(glob(os.path.join(path, '*.csv'))):\n",
    "    file = file.split('/')\n",
    "    file = file[-1]\n",
    "\n",
    "    df = spark.read.format('csv').option('header', True).load(f'/home/jovyan/stocks10/{file}')\n",
    "    file = file.split('.')\n",
    "    stock_name = file[-2]\n",
    "    \n",
    "#Transform\n",
    "    df = df.withColumn(f'{stock_name}', (df['Close'] - df['Open'])/ df['Open'])\n",
    "    df = df.drop('High', 'Low', 'Adj Close', 'Volume', 'Open', 'Close')\n",
    "    stocks = stocks.join(df, on= 'Date', how = 'fullouter')\n",
    "\n",
    "stocks = stocks.withColumn(\"Year\", year(\"Date\")).withColumn(\"Month\", month(\"Date\")).repartition(1)\n",
    "\n",
    "#Load\n",
    "stocks.write.format('parquet').mode('overwrite').partitionBy(['year', 'month']).save(f'/home/jovyan/parquet/')\n",
    "\n",
    "stocks.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./year=1968/month=2/.part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet.crc\r\n",
      "./year=1968/month=3\r\n",
      "./year=1968/month=3/part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet\r\n",
      "./year=1968/month=3/.part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet.crc\r\n",
      "./year=1968/month=8\r\n",
      "./year=1968/month=8/part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet\r\n",
      "./year=1968/month=8/.part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet.crc\r\n",
      "./year=1968/month=9\r\n",
      "./year=1968/month=9/part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet\r\n",
      "./year=1968/month=9/.part-00000-e1f0c7ba-3d25-404b-a73b-5ab49c25d7ef.c000.snappy.parquet.crc\r\n"
     ]
    }
   ],
   "source": [
    "!cd /home/jovyan/parquet/ && find | tail -n 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
